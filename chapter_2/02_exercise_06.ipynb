{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 2 â€“ End-to-end Machine Learning project**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook contains the solution to the exercise 6 in chapter 2*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: _Try to implement the `StandardScalerClone` class again from scratch, then add support for the `inverse_transform()` method: executing `scaler.inverse_transform(scaler.fit_transform(X))` should return an array very close to `X`. Then add support for feature names: set `feature_names_in_` in the `fit()` method if the input is a DataFrame. This attribute should be a NumPy array of column names. Lastly, implement the `get_feature_names_out()` method: it should have one optional `input_features=None` argument. If passed, the method should check that its length matches `n_features_in_`, and it should match `feature_names_in_` if it is defined, then `input_features` should be returned. If `input_features` is `None`, then the method should return `feature_names_in_` if it is defined or `np.array([\"x0\", \"x1\", ...])` with length `n_features_in_` otherwise._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "\n",
    "class StandardScalerClone(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, with_mean=True):  # no *args or **kwargs!\n",
    "        self.with_mean = with_mean\n",
    "\n",
    "    def fit(self, X, y=None):  # y is required even though we don't use it\n",
    "        X_orig = X\n",
    "        X = check_array(X)  # checks that X is an array with finite float values\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        self.scale_ = X.std(axis=0)\n",
    "        self.n_features_in_ = X.shape[1]  # every estimator stores this in fit()\n",
    "        if hasattr(X_orig, \"columns\"):\n",
    "            self.feature_names_in_ = np.array(X_orig.columns, dtype=object)\n",
    "        return self  # always return self!\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)  # looks for learned attributes (with trailing _)\n",
    "        X = check_array(X)\n",
    "        if self.n_features_in_ != X.shape[1]:\n",
    "            raise ValueError(\"Unexpected number of features\")\n",
    "        if self.with_mean:\n",
    "            X = X - self.mean_\n",
    "        return X / self.scale_\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        if self.n_features_in_ != X.shape[1]:\n",
    "            raise ValueError(\"Unexpected number of features\")\n",
    "        X = X * self.scale_\n",
    "        return X + self.mean_ if self.with_mean else X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            return getattr(self, \"feature_names_in_\",\n",
    "                           [f\"x{i}\" for i in range(self.n_features_in_)])\n",
    "        else:\n",
    "            if len(input_features) != self.n_features_in_:\n",
    "                raise ValueError(\"Invalid number of features\")\n",
    "            if hasattr(self, \"feature_names_in_\") and not np.all(\n",
    "                self.feature_names_in_ == input_features\n",
    "            ):\n",
    "                raise ValueError(\"input_features â‰  feature_names_in_\")\n",
    "            return input_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our custom transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    " \n",
    "check_estimator(StandardScalerClone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors, that's a great start, we respect the Scikit-Learn API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ensure the transformation works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 3)\n",
    "\n",
    "scaler = StandardScalerClone()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "assert np.allclose(X_scaled, (X - X.mean(axis=0)) / X.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about setting `with_mean=False`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScalerClone(with_mean=False)\n",
    "X_scaled_uncentered = scaler.fit_transform(X)\n",
    "\n",
    "assert np.allclose(X_scaled_uncentered, X / X.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And does the inverse work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScalerClone()\n",
    "X_back = scaler.inverse_transform(scaler.fit_transform(X))\n",
    "\n",
    "assert np.allclose(X, X_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the feature names out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(scaler.get_feature_names_out() == [\"x0\", \"x1\", \"x2\"])\n",
    "assert np.all(scaler.get_feature_names_out([\"a\", \"b\", \"c\"]) == [\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we fit a DataFrame, are the feature in and out ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\": np.random.rand(100), \"b\": np.random.rand(100)})\n",
    "scaler = StandardScalerClone()\n",
    "X_scaled = scaler.fit_transform(df)\n",
    "\n",
    "assert np.all(scaler.feature_names_in_ == [\"a\", \"b\"])\n",
    "assert np.all(scaler.get_feature_names_out() == [\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good! That's all for today! ðŸ˜€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You already know quite a lot about Machine Learning. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
